{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*October 2019 | Hilary Goh, Perth - Australia*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes notebook based on the following references\n",
    "\n",
    "Sklearn Iris: https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "Titantic blog: https://www.sicara.ai/blog/2018-02-28-naive-bayes-classification-sklearn\n",
    "* nice explanation of Navie Bayes\n",
    "* also talks about NaNs and how to deal with them\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.datasets import load_iris \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "x = iris['data']\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris #note Pandas is not being used in this example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data splits and train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split( x, y, random_state = 42) \n",
    "# try different random states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf = clf.fit(x_train, y_train)\n",
    "clf.predict(x_test)\n",
    "# make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" \n",
    "      % (x_test.shape[0],(y_test != y_pred).sum())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test, y_test)\n",
    "# close to 1 is a good result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(x_train, columns=iris.feature_names)\n",
    "train['target'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virginica = train[train.target==2]\n",
    "setosa = train[train.target==1]\n",
    "versicolor =train[train.target ==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.feature_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.distplot(virginica['sepal length (cm)'])\n",
    "sns.distplot(setosa['sepal length (cm)'])\n",
    "sns.distplot(versicolor['sepal length (cm)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.class_prior_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0,1,2]:\n",
    "    print(f'number of class {i} is {(y_train == i).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which dataset to use?\n",
    "\n",
    "Stanford: https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/problem12.html\n",
    "* use this one if you don't want to make a Kaggle acount\n",
    "* smaller dataset (less classes)\n",
    "\n",
    "Kaggle: https://www.kaggle.com/c/titanic\n",
    "* requires Kaggle account to download data\n",
    "* larger dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* assuming this is a new notebook/experiment to above\n",
    "* also in a new notebook try typing in the code rather than copying, this is a good way to practise python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"titanic.csv\")\n",
    "# you will get an error here because the dataset is not saved on your PC/locally\n",
    "# find the Titanic dataset - see blog\n",
    "# save this dataset to the same directory as this Jupyter notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting categorical data to numerical i.e. Male = 0, Female = 1\n",
    "\n",
    "Note which Titanic dataset you are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variable to numeric\n",
    "data[\"Sex_cleaned\"]=np.where(data[\"Sex\"]==\"male\",0,1)\n",
    "#data[\"Embarked_cleaned\"]=np.where(data[\"Embarked\"]==\"S\",0,\n",
    "#                                  np.where(data[\"Embarked\"]==\"C\",1,\n",
    "#                                           np.where(data[\"Embarked\"]==\"Q\",2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning dataset of NaN\n",
    "data=data[[\n",
    "    \"Survived\",\n",
    "    \"Pclass\",\n",
    "    \"Sex_cleaned\",\n",
    "    \"Age\",\n",
    "    \"SibSp\",\n",
    "    \"Parch\",\n",
    "    \"Fare\",\n",
    "]].dropna(axis=0, how='any')\n",
    "# changed column titles in csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data splits and train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset in training and test datasets\n",
    "X_train, X_test = train_test_split(data, test_size=0.5, random_state=int(time.time()))\n",
    "#X_train, X_test = train_test_split(data, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier\n",
    "gnb = GaussianNB()\n",
    "used_features =[\n",
    "    \"Pclass\",\n",
    "    \"Sex_cleaned\",\n",
    "    \"Age\",\n",
    "    \"SibSp\",\n",
    "    \"Parch\",\n",
    "    \"Fare\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier\n",
    "gnb.fit(X_train[used_features].values,X_train[\"Survived\"])\n",
    "y_pred = gnb.predict(X_test[used_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n",
    "      .format(X_test.shape[0],(X_test[\"Survived\"] != y_pred).sum(),\n",
    "    100*(1-(X_test[\"Survived\"] != y_pred).sum()/X_test.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustration with 1 feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know probability of survival when we consider the fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_survival=np.mean(X_train[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_not_survival=1-mean_survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Survival prob = {:03.2f}%, Not survival prob = {:03.2f}%\"\n",
    "      .format(100*mean_survival,100*mean_not_survival))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1502/2224 \n",
    "# died/total check, % who died \n",
    "# is it the same as above? \n",
    "#why might it be different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fare_survived = np.mean(X_train[X_train[\"Survived\"]==1][\"Fare\"]) # 1 is survived, 0 is died\n",
    "std_fare_survived = np.std(X_train[X_train[\"Survived\"]==1][\"Fare\"])\n",
    "mean_fare_not_survived = np.mean(X_train[X_train[\"Survived\"]==0][\"Fare\"])\n",
    "std_fare_not_survived = np.std(X_train[X_train[\"Survived\"]==0][\"Fare\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean_fare_survived = {:03.2f}\".format(mean_fare_survived))\n",
    "print(\"std_fare_survived = {:03.2f}\".format(std_fare_survived))\n",
    "print(\"mean_fare_not_survived = {:03.2f}\".format(mean_fare_not_survived))\n",
    "print(\"std_fare_not_survived = {:03.2f}\".format(std_fare_not_survived))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check out the rest of the blog for further discussion of the results\n",
    "\n",
    "FIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
